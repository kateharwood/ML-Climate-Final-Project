{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import numpy as np"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "source": [
    "first_data = pd.read_csv('../../1995_Street_Tree_Census.csv')\n",
    "second_data = pd.read_csv('../../2005_Street_Tree_Census.csv')\n",
    "third_data = pd.read_csv('../../2015_Street_Tree_Census.csv')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/kateharwood/opt/miniconda3/envs/climate/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3185: DtypeWarning: Columns (37) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "source": [
    "# Extract the columns we care about\n",
    "first_data = first_data[[\"Latitude\", \"Longitude\", \"Borough\", \"Zip Codes\", \"Spc_Latin\", \"Diameter\", \"Condition\"]]\n",
    "second_data = second_data[[\"latitude\", \"longitude\", \"boroname\", \"zipcode\", \"spc_latin\", \"tree_dbh\", \"status\"]]\n",
    "third_data = third_data[[\"latitude\", \"longitude\", \"borough\", \"postcode\", \"spc_latin\", \"tree_dbh\", \"status\", \"health\"]]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Standardize all health statuses across the 2005 and 2015 datasets"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "source": [
    "\n",
    "first_data\n",
    "first_data.dtypes\n",
    "first_data.Condition.unique()\n",
    "# first_data.Borough.unique()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array(['Unknown', 'Good', 'Excellent', 'Poor', 'Dead', 'Stump',\n",
       "       'Planting Space', 'Shaft', 'Fair', 'Critical'], dtype=object)"
      ]
     },
     "metadata": {},
     "execution_count": 123
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "source": [
    "# Rename \"Excellent\" to \"Good\", rename \"Good\" to \"Fair\"\n",
    "second_data.status[second_data['status'] == \"Good\"] = \"Fair\"\n",
    "second_data.status[second_data['status'] == \"Excellent\"] = \"Good\"\n",
    "second_data = second_data.rename(columns={\"status\": \"health\"})\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/var/folders/z7/x5j_gv2x6f92wlfl832cwwy80000gn/T/ipykernel_85224/1737469685.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  second_data.status[second_data['status'] == \"Excellent\"] = \"Good\"\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array(['Fair', 'Poor', 'Good', 'Dead'], dtype=object)"
      ]
     },
     "metadata": {},
     "execution_count": 124
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "source": [
    "# Set all status to be \"Alive\" or \"Dead\" (remove \"Stump\")\n",
    "third_data.health[(third_data['health'].isna()) & (third_data['status'] != \"Alive\")] = \"Dead\"\n",
    "# TODO remove the one alive and health is na row\n",
    "\n",
    "# third_data.dtypes\n",
    "third_data.health.unique()\n",
    "# third_data.status.unique()\n",
    "# third_data.borough.unique()\n",
    "# third_data.root_stone\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array(['Fair', 'Good', 'Poor', 'Dead', nan], dtype=object)"
      ]
     },
     "metadata": {},
     "execution_count": 125
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "source": [
    "# Group trees into geospatial segments by lat and long\n",
    "step = 0.00000001 # This should be about 1/4-1/2 a city block \n",
    "to_bin = lambda x: np.floor(x / step) * step\n",
    "second_data[\"latBin\"] = to_bin(second_data.latitude)\n",
    "second_data[\"lonBin\"] = to_bin(second_data.longitude)\n",
    "groups = second_data.groupby([\"latBin\", \"lonBin\"])\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "source": [
    "groups.size().sort_values().value_counts()\n",
    "# groups.ngroup(ascending=False)+1\n",
    "\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1       154448\n",
       "2        49446\n",
       "3        23575\n",
       "4        15112\n",
       "5         8677\n",
       "         ...  \n",
       "71           1\n",
       "54           1\n",
       "66           1\n",
       "64           1\n",
       "8840         1\n",
       "Length: 80, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 128
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.7",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.10.0 64-bit ('climate': conda)"
  },
  "interpreter": {
   "hash": "861821414808db1f617223c6d4569b19cc725b2a2a07694c74cd2c6384ef391b"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}