{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "first_data = pd.read_csv('data/1995_Street_Tree_Census.csv')\n",
    "second_data = pd.read_csv('data/2005_Street_Tree_Census.csv')\n",
    "third_data = pd.read_csv('data/2015_Street_Tree_Census.csv')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/kateharwood/opt/miniconda3/envs/climate/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3185: DtypeWarning: Columns (37) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Standardize feature columns across datasets"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "source": [
    "# Extract the columns we care about\n",
    "first_data = first_data[[\"Latitude\", \"Longitude\", \"Borough\", \"Postcode_Original\", \"Spc_Latin\", \"Diameter\", \"Condition\"]]\n",
    "second_data = second_data[[\"latitude\", \"longitude\", \"boroname\", \"zipcode\", \"spc_latin\", \"tree_dbh\", \"status\"]]\n",
    "third_data = third_data[[\"latitude\", \"longitude\", \"borough\", \"postcode\", \"spc_latin\", \"tree_dbh\", \"status\", \"health\"]]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "source": [
    "# Remove NaN rows \n",
    "# TODO should I remove all NaN rows from all datasets?\n",
    "# TODO is this actually doing anything now? that it is changed to postcode original\n",
    "first_data = first_data[first_data['Postcode_Original'].notna()]\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "source": [
    "first_data = first_data.rename(columns={\"Postcode_Original\": \"zipcode\", \"Borough\": \"borough\", \"Spc_Latin\": \"spc_latin\", \"Diameter\": \"tree_diameter\"})\n",
    "second_data = second_data.rename(columns={\"boroname\": \"borough\", \"tree_dbh\": \"tree_diameter\"})\n",
    "second_data.borough[second_data['borough'] == 5] = 'Staten Island'\n",
    "third_data = third_data.rename(columns={'postcode': 'zipcode'})\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/var/folders/z7/x5j_gv2x6f92wlfl832cwwy80000gn/T/ipykernel_14706/3548259356.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  second_data.borough[second_data['borough'] == 5] = 'Staten Island'\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "source": [
    "first_data = first_data[first_data['spc_latin'].notna()]\n",
    "first_data['spc_latin'] = first_data['spc_latin'].str.lower()\n",
    "second_data = second_data[second_data['spc_latin'].notna()]\n",
    "second_data['spc_latin'] = second_data['spc_latin'].str.lower()\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Standardize all health statuses across the 2005 and 2015 datasets"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [
    "# Rename \"Excellent\" to \"Good\", rename \"Good\" to \"Fair\"\n",
    "second_data.status[second_data['status'] == \"Good\"] = \"Fair\"\n",
    "second_data.status[second_data['status'] == \"Excellent\"] = \"Good\"\n",
    "second_data = second_data.rename(columns={\"status\": \"health\"})\n",
    "second_data.health.unique()\n",
    "\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/var/folders/z7/x5j_gv2x6f92wlfl832cwwy80000gn/T/ipykernel_14706/16073105.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  second_data.status[second_data['status'] == \"Good\"] = \"Fair\"\n",
      "/var/folders/z7/x5j_gv2x6f92wlfl832cwwy80000gn/T/ipykernel_14706/16073105.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  second_data.status[second_data['status'] == \"Excellent\"] = \"Good\"\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array(['Fair', 'Poor', 'Good', 'Dead'], dtype=object)"
      ]
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "source": [
    "# Set all status to be \"Alive\" or \"Dead\" (remove \"Stump\")\n",
    "third_data.health[(third_data['health'].isna()) & (third_data['status'] != \"Alive\")] = \"Dead\"\n",
    "# Remove the row with status == alive and health is na\n",
    "third_data.drop(third_data[third_data['health'].isna()].index, inplace = True)\n",
    "# Drop extra status column\n",
    "third_data.drop(columns=['status'], inplace=True)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/var/folders/z7/x5j_gv2x6f92wlfl832cwwy80000gn/T/ipykernel_14706/3319506031.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  third_data.health[(third_data['health'].isna()) & (third_data['status'] != \"Alive\")] = \"Dead\"\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "source": [
    "# Make categorical health data numeric\n",
    "health_dict = {'Dead':0, 'Poor':1, 'Fair':2, 'Good':3}\n",
    "second_data['health_status'] = second_data['health'].map(health_dict)\n",
    "third_data['health_status'] = third_data[\"health\"].map(health_dict)\n",
    "second_data"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>borough</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>spc_latin</th>\n",
       "      <th>tree_diameter</th>\n",
       "      <th>health</th>\n",
       "      <th>health_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40.632653</td>\n",
       "      <td>-74.000245</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>11219</td>\n",
       "      <td>pyrus calleryana</td>\n",
       "      <td>6</td>\n",
       "      <td>Fair</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40.620084</td>\n",
       "      <td>-73.901453</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>11234</td>\n",
       "      <td>platanus acerifolia</td>\n",
       "      <td>6</td>\n",
       "      <td>Fair</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40.617996</td>\n",
       "      <td>-73.899111</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>11234</td>\n",
       "      <td>acer platanoides          crimson king</td>\n",
       "      <td>13</td>\n",
       "      <td>Fair</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40.619694</td>\n",
       "      <td>-73.901003</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>11234</td>\n",
       "      <td>platanus acerifolia</td>\n",
       "      <td>13</td>\n",
       "      <td>Fair</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40.618323</td>\n",
       "      <td>-73.899467</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>11234</td>\n",
       "      <td>platanus acerifolia</td>\n",
       "      <td>15</td>\n",
       "      <td>Fair</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592367</th>\n",
       "      <td>40.586260</td>\n",
       "      <td>-74.148797</td>\n",
       "      <td>Staten Island</td>\n",
       "      <td>10314</td>\n",
       "      <td>platanus acerifolia</td>\n",
       "      <td>9</td>\n",
       "      <td>Fair</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592368</th>\n",
       "      <td>40.586090</td>\n",
       "      <td>-74.149013</td>\n",
       "      <td>Staten Island</td>\n",
       "      <td>10314</td>\n",
       "      <td>acer saccharinum</td>\n",
       "      <td>7</td>\n",
       "      <td>Fair</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592369</th>\n",
       "      <td>40.585802</td>\n",
       "      <td>-74.149156</td>\n",
       "      <td>Staten Island</td>\n",
       "      <td>10314</td>\n",
       "      <td>acer platanoides          crimson king</td>\n",
       "      <td>5</td>\n",
       "      <td>Fair</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592370</th>\n",
       "      <td>40.585802</td>\n",
       "      <td>-74.149156</td>\n",
       "      <td>Staten Island</td>\n",
       "      <td>10314</td>\n",
       "      <td>acer platanoides          crimson king</td>\n",
       "      <td>9</td>\n",
       "      <td>Fair</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592371</th>\n",
       "      <td>40.585802</td>\n",
       "      <td>-74.149156</td>\n",
       "      <td>Staten Island</td>\n",
       "      <td>10314</td>\n",
       "      <td>acer platanoides          crimson king</td>\n",
       "      <td>2</td>\n",
       "      <td>Fair</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>592372 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         latitude  longitude        borough  zipcode  \\\n",
       "0       40.632653 -74.000245       Brooklyn    11219   \n",
       "1       40.620084 -73.901453       Brooklyn    11234   \n",
       "2       40.617996 -73.899111       Brooklyn    11234   \n",
       "3       40.619694 -73.901003       Brooklyn    11234   \n",
       "4       40.618323 -73.899467       Brooklyn    11234   \n",
       "...           ...        ...            ...      ...   \n",
       "592367  40.586260 -74.148797  Staten Island    10314   \n",
       "592368  40.586090 -74.149013  Staten Island    10314   \n",
       "592369  40.585802 -74.149156  Staten Island    10314   \n",
       "592370  40.585802 -74.149156  Staten Island    10314   \n",
       "592371  40.585802 -74.149156  Staten Island    10314   \n",
       "\n",
       "                                     spc_latin  tree_diameter health  \\\n",
       "0                             pyrus calleryana              6   Fair   \n",
       "1                          platanus acerifolia              6   Fair   \n",
       "2       acer platanoides          crimson king             13   Fair   \n",
       "3                          platanus acerifolia             13   Fair   \n",
       "4                          platanus acerifolia             15   Fair   \n",
       "...                                        ...            ...    ...   \n",
       "592367                     platanus acerifolia              9   Fair   \n",
       "592368                        acer saccharinum              7   Fair   \n",
       "592369  acer platanoides          crimson king              5   Fair   \n",
       "592370  acer platanoides          crimson king              9   Fair   \n",
       "592371  acer platanoides          crimson king              2   Fair   \n",
       "\n",
       "        health_status  \n",
       "0                   2  \n",
       "1                   2  \n",
       "2                   2  \n",
       "3                   2  \n",
       "4                   2  \n",
       "...               ...  \n",
       "592367              2  \n",
       "592368              2  \n",
       "592369              2  \n",
       "592370              2  \n",
       "592371              2  \n",
       "\n",
       "[592372 rows x 8 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 45
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Group trees into geospatial segments that match across datasets"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "source": [
    "# Group trees into geospatial segments by lat and long\n",
    "# step = 0.00000001 # This should be about 1/4-1/2 a city block \n",
    "# step = 0.001\n",
    "step = 0.0005 # Actually no this should be about 1/2 block ish, TODO\n",
    "to_bin = lambda x: np.floor(x / step) * step\n",
    "second_data[\"latBin\"] = to_bin(second_data.latitude)\n",
    "second_data[\"lonBin\"] = to_bin(second_data.longitude)\n",
    "\n",
    "# Drop all rows where lat or long is 0\n",
    "second_data.drop(second_data[second_data['latBin'] == 0].index, inplace = True)\n",
    "second_data.drop(second_data[second_data['lonBin'] == 0].index, inplace = True)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "source": [
    "# Only keep the rows whose zipcodes overlap across datasets\n",
    "zipcodes_intersection = set(first_data['zipcode']).intersection(set(second_data['zipcode'])).intersection(third_data['zipcode'])\n",
    "first_data = first_data[first_data['zipcode'].isin(zipcodes_intersection)]\n",
    "second_data = second_data[second_data['zipcode'].isin(zipcodes_intersection)]\n",
    "third_data = third_data[third_data['zipcode'].isin(zipcodes_intersection)]\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "source": [
    "# Set latBin and lonBin values to match across second and third datasets\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "third_data[\"latBin\"] = 0\n",
    "third_data[\"lonBin\"] = 0\n",
    "second_data = second_data.sort_values('zipcode')\n",
    "third_data = third_data.sort_values('zipcode')\n",
    "\n",
    "latBins = []\n",
    "lonBins = []\n",
    "for zipcode in sorted(list(zipcodes_intersection)):\n",
    "    test2 = second_data[second_data['zipcode'] == zipcode]\n",
    "    test3 = third_data[third_data['zipcode'] == zipcode]\n",
    "    temp = test2[['latBin','lonBin']].iloc[np.argmin(cdist(test3[['latitude','longitude']], test2[['latBin','lonBin']], metric='euclidean'), axis=1)]\n",
    "    latBins.extend(list(temp.latBin))\n",
    "    lonBins.extend(list(temp.lonBin))\n",
    "third_data['latBin'] = latBins\n",
    "third_data['lonBin'] = lonBins\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "source": [
    "# Do the same for the first data\n",
    "first_data[\"latBin\"] = 0\n",
    "first_data[\"lonBin\"] = 0\n",
    "second_data = second_data.sort_values('zipcode')\n",
    "first_data = first_data.sort_values('zipcode')\n",
    "\n",
    "latBins = []\n",
    "lonBins = []\n",
    "for zipcode in sorted(list(zipcodes_intersection)):\n",
    "    test2 = second_data[second_data['zipcode'] == zipcode]\n",
    "    test1 = first_data[first_data['zipcode'] == zipcode]\n",
    "    temp = test2[['latBin','lonBin']].iloc[np.argmin(cdist(test1[['Latitude','Longitude']], test2[['latBin','lonBin']], metric='euclidean'), axis=1)]\n",
    "    latBins.extend(list(temp.latBin))\n",
    "    lonBins.extend(list(temp.lonBin))\n",
    "first_data['latBin'] = latBins\n",
    "first_data['lonBin'] = lonBins\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "source": [
    "# Drop the rows whose actual lat and long differ too much from their latBin and lonBin\n",
    "\n",
    "third_data['lonDistance'] = (third_data['lonBin']-third_data['longitude']).abs()\n",
    "third_data['latDistance'] = (third_data['latBin']-third_data['latitude']).abs()\n",
    "\n",
    "third_data.drop(third_data[third_data['health'].isna()].index, inplace = True)\n",
    "\n",
    "third_data.drop(third_data[third_data['lonDistance'] > 0.001].index, inplace = True) #\"neighborhood or street\" from wikipedia\n",
    "third_data.drop(third_data[third_data['latDistance'] > 0.001].index, inplace = True) #\"neighborhood or street\" from wikipedia\n",
    "\n",
    "\n",
    "first_data['lonDistance'] = (first_data['lonBin']-first_data['Longitude']).abs()\n",
    "first_data['latDistance'] = (first_data['latBin']-first_data['Latitude']).abs()\n",
    "\n",
    "first_data.drop(first_data[first_data['lonDistance'] > 0.001].index, inplace = True) #\"neighborhood or street\" from wikipedia\n",
    "first_data.drop(first_data[first_data['latDistance'] > 0.001].index, inplace = True) #\"neighborhood or street\" from wikipedia\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Merge the three datasets \n",
    "### Join the 1995 (first_data) features to the 2005 (second_data) health status values (matching on latBin and lonBin)\n",
    "### Join the 2005 features to the 2015 health status values (matching on latBin and lonBin)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "source": [
    "# Average the health data based on latBin/lonBin groups (and round to nearest whole number aka nearest health category)\n",
    "second_data['avg_health_round'] = second_data.groupby([\"latBin\", \"lonBin\"])['health_status'].transform('mean').round(0)\n",
    "third_data['avg_health_round'] = third_data.groupby([\"latBin\", \"lonBin\"])['health_status'].transform('mean').round(0)\n",
    "second_data['avg_health'] = second_data.groupby([\"latBin\", \"lonBin\"])['health_status'].transform('mean')\n",
    "third_data['avg_health'] = third_data.groupby([\"latBin\", \"lonBin\"])['health_status'].transform('mean')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "source": [
    "# Keep only necessary features and merge dataframes\n",
    "\n",
    "second_data_health = second_data.drop(columns={'tree_diameter', 'borough', 'health', 'health_status', 'latitude', 'longitude', 'spc_latin', 'zipcode'})\n",
    "first_data_features = first_data.drop(columns={'Latitude', 'Longitude', 'Condition'})\n",
    "second_data_health = second_data_health.drop_duplicates(subset=['avg_health', 'avg_health_round', 'latBin','lonBin'])\n",
    "\n",
    "merged_first_second = first_data_features.merge(second_data_health, on=['latBin', 'lonBin'], how=\"inner\")\n",
    "merged_first_second\n",
    "\n",
    "third_data_health = third_data.drop(['borough', 'zipcode', 'spc_latin', 'tree_dbh', 'health', 'health_status', 'latitude', 'longitude'], axis=1)\n",
    "second_data_features = second_data.drop(columns=['avg_health', 'avg_health_round', 'health', 'health_status', 'latitude', 'longitude'])\n",
    "third_data_health = third_data_health.drop_duplicates(subset=['avg_health','avg_health_round', 'latBin','lonBin'])\n",
    "\n",
    "merged_second_third = second_data_features.merge(third_data_health, on=['latBin', 'lonBin'], how=\"inner\")\n",
    "merged_second_third\n",
    "\n",
    "# TODO note that the species still don't match up"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>borough</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>spc_latin</th>\n",
       "      <th>tree_diameter</th>\n",
       "      <th>latBin</th>\n",
       "      <th>lonBin</th>\n",
       "      <th>lonDistance</th>\n",
       "      <th>latDistance</th>\n",
       "      <th>avg_health_round</th>\n",
       "      <th>avg_health</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Manhattan</td>\n",
       "      <td>10001</td>\n",
       "      <td>tilia cordata</td>\n",
       "      <td>6</td>\n",
       "      <td>40.749</td>\n",
       "      <td>-73.9995</td>\n",
       "      <td>1.634000e-05</td>\n",
       "      <td>0.000196</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Manhattan</td>\n",
       "      <td>10001</td>\n",
       "      <td>robinia pseudoacacia</td>\n",
       "      <td>8</td>\n",
       "      <td>40.749</td>\n",
       "      <td>-73.9995</td>\n",
       "      <td>1.634000e-05</td>\n",
       "      <td>0.000196</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Manhattan</td>\n",
       "      <td>10001</td>\n",
       "      <td>quercus palustris</td>\n",
       "      <td>9</td>\n",
       "      <td>40.749</td>\n",
       "      <td>-73.9995</td>\n",
       "      <td>1.634000e-05</td>\n",
       "      <td>0.000196</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Manhattan</td>\n",
       "      <td>10001</td>\n",
       "      <td>platanus acerifolia</td>\n",
       "      <td>14</td>\n",
       "      <td>40.749</td>\n",
       "      <td>-73.9995</td>\n",
       "      <td>1.634000e-05</td>\n",
       "      <td>0.000196</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Manhattan</td>\n",
       "      <td>10001</td>\n",
       "      <td>zelkova serrata</td>\n",
       "      <td>5</td>\n",
       "      <td>40.749</td>\n",
       "      <td>-73.9995</td>\n",
       "      <td>1.634000e-05</td>\n",
       "      <td>0.000196</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544364</th>\n",
       "      <td>Queens</td>\n",
       "      <td>11694</td>\n",
       "      <td>platanus acerifolia</td>\n",
       "      <td>16</td>\n",
       "      <td>40.581</td>\n",
       "      <td>-73.8530</td>\n",
       "      <td>1.771800e-04</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544365</th>\n",
       "      <td>Queens</td>\n",
       "      <td>11694</td>\n",
       "      <td>acer platanoides</td>\n",
       "      <td>11</td>\n",
       "      <td>40.579</td>\n",
       "      <td>-73.8455</td>\n",
       "      <td>8.304000e-05</td>\n",
       "      <td>0.000279</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.454545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544366</th>\n",
       "      <td>Queens</td>\n",
       "      <td>11694</td>\n",
       "      <td>acer platanoides</td>\n",
       "      <td>14</td>\n",
       "      <td>40.579</td>\n",
       "      <td>-73.8455</td>\n",
       "      <td>8.304000e-05</td>\n",
       "      <td>0.000279</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.454545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544367</th>\n",
       "      <td>Queens</td>\n",
       "      <td>11694</td>\n",
       "      <td>acer platanoides</td>\n",
       "      <td>14</td>\n",
       "      <td>40.579</td>\n",
       "      <td>-73.8455</td>\n",
       "      <td>8.304000e-05</td>\n",
       "      <td>0.000279</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.454545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544368</th>\n",
       "      <td>Queens</td>\n",
       "      <td>11694</td>\n",
       "      <td>platanus acerifolia</td>\n",
       "      <td>10</td>\n",
       "      <td>40.579</td>\n",
       "      <td>-73.8530</td>\n",
       "      <td>9.999999e-08</td>\n",
       "      <td>0.000193</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.833333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>544369 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          borough  zipcode             spc_latin  tree_diameter  latBin  \\\n",
       "0       Manhattan    10001         tilia cordata              6  40.749   \n",
       "1       Manhattan    10001  robinia pseudoacacia              8  40.749   \n",
       "2       Manhattan    10001     quercus palustris              9  40.749   \n",
       "3       Manhattan    10001   platanus acerifolia             14  40.749   \n",
       "4       Manhattan    10001       zelkova serrata              5  40.749   \n",
       "...           ...      ...                   ...            ...     ...   \n",
       "544364     Queens    11694   platanus acerifolia             16  40.581   \n",
       "544365     Queens    11694      acer platanoides             11  40.579   \n",
       "544366     Queens    11694      acer platanoides             14  40.579   \n",
       "544367     Queens    11694      acer platanoides             14  40.579   \n",
       "544368     Queens    11694   platanus acerifolia             10  40.579   \n",
       "\n",
       "         lonBin   lonDistance  latDistance  avg_health_round  avg_health  \n",
       "0      -73.9995  1.634000e-05     0.000196               2.0    2.111111  \n",
       "1      -73.9995  1.634000e-05     0.000196               2.0    2.111111  \n",
       "2      -73.9995  1.634000e-05     0.000196               2.0    2.111111  \n",
       "3      -73.9995  1.634000e-05     0.000196               2.0    2.111111  \n",
       "4      -73.9995  1.634000e-05     0.000196               2.0    2.111111  \n",
       "...         ...           ...          ...               ...         ...  \n",
       "544364 -73.8530  1.771800e-04     0.000005               3.0    3.000000  \n",
       "544365 -73.8455  8.304000e-05     0.000279               2.0    2.454545  \n",
       "544366 -73.8455  8.304000e-05     0.000279               2.0    2.454545  \n",
       "544367 -73.8455  8.304000e-05     0.000279               2.0    2.454545  \n",
       "544368 -73.8530  9.999999e-08     0.000193               3.0    2.833333  \n",
       "\n",
       "[544369 rows x 10 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 53
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "source": [
    "# Save dataset for use in models\n",
    "final_data = merged_first_second.append(merged_second_third)\n",
    "final_data.to_csv('data/parsed_data.csv')\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "source": [
    "# second_data_features.sort_values(['latBin', 'lonBin']).head(20)\n",
    "# merged_second_third.sort_values('avg_health')\n",
    "# merged_second_third.avg_health.unique()\n",
    "# third_data_health.avg_health.unique()\n",
    "# # second_data_health.avg_health.unique()\n",
    "# third_data_health[third_data_health['latBin'] == 40.9110].sort_values(['latBin', 'lonBin'])\n",
    "# third_data_health.sort_values(['latBin', 'lonBin']).tail(83)\n",
    "\n",
    "# merged_second_third[merged_second_third['borough'].isna()]\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "source": [
    "# second_data_features.sort_values(['latBin', 'lonBin']).tail(50)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "source": [
    "# third_data_health.sort_values(['latBin', 'lonBin']).head(20)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# df['avg_result'] = df.groupby(['a', 'b'])['result'].transform('mean')\n",
    "# groups.size().sort_values().value_counts()\n",
    "# groups.size().sort_values()\n",
    "\n",
    "# third_data.sort_values(by='latBin', ascending=False).head(50)\n",
    "\n",
    "# second_data.sort_values(by='latBin', ascending=False).head(10)\n",
    "\n",
    "# third_data.sort_values(by='latBin', ascending=False)\n",
    "# third_data[third_data['latBin'] > 40.912].sort_values(by='latBin', ascending=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# third_data = pd.read_csv('../data/2015_data.csv')\n",
    "# third_data.drop(columns=['Unnamed: 0'], inplace = True)\n",
    "# third_data\n",
    "\n",
    "# first_data = pd.read_csv('../data/1995_data.csv')\n",
    "# first_data.drop(columns=['Unnamed: 0'], inplace = True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Do the same for the 1995 data\n",
    "# Take 13ish mins\n",
    "# TODO nope\n",
    "\n",
    "# first_data[\"latBin\"] = 0\n",
    "# first_data[\"lonBin\"] = 0\n",
    "# binValues = sorted(list(dict.fromkeys(list(zip(second_data['latBin'], second_data['lonBin'])))))\n",
    "\n",
    "# for latBinValue, lonBinValue in binValues:\n",
    "#     first_data.loc[first_data['Latitude'] >= latBinValue, ['latBin', 'lonBin']] = latBinValue, lonBinValue\n",
    "\n",
    "# for latBinValue in sorted(second_data['latBin'].unique()):\n",
    "#     first_data.loc[first_data['Latitude'] >= latBinValue, ['latBin']] = latBinValue\n",
    "\n",
    "# for lonBinValue in sorted(second_data['lonBin'].unique()):\n",
    "#     first_data.loc[first_data['Longitude'] >= lonBinValue, ['lonBin']] = lonBinValue\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# third_data[third_data['zipcode'] == zipcode]['latBin'] = latBins\n",
    "# third_data[third_data['zipcode'] == zipcode]['lonBin'] = lonBins\n",
    "# third_data\n",
    "# second_data[['latBin','lonBin']] = \\\n",
    "#   second_data[['latBin','lonBin']].iloc[np.argmin(cdist(third_data[['latitude','longitude']], second_data[['latBin','lonBin']],\n",
    "#   metric='euclidean' ), axis=1),:].copy().reset_index(drop=True)\n",
    "# third_data\n",
    "# test3 = third_data.head(5000)\n",
    "# test2 = second_data.head(5000)\n",
    "# np.argmin(cdist(test3[['latitude','longitude']], test2[['latBin','lonBin']], metric='euclidean'))\n",
    "# cdist(test3[['latitude','longitude']], test2[['latBin','lonBin']], metric='euclidean')\n",
    "\n",
    "# test2 = second_data.head(5)\n",
    "# test3 = third_data.head(5)\n",
    "# # print(test2)\n",
    "# # print(test3)\n",
    "# test3[['latBin', 'lonBin']] = test2[['latBin','lonBin']].iloc[np.argmin(cdist(test3[['latitude','longitude']], test2[['latBin','lonBin']], metric='euclidean'), axis=1)].copy().reset_index(drop=True)\n",
    "# test3\n",
    "# third_data.sort_values('zipcode')\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# second_data.head(100)\n",
    "# groups = second_data.groupby(['latBin', 'lonBin'])\n",
    "\n",
    "# # groups.size().sort_values().tail(50)\n",
    "\n",
    "# groups.size()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Set latBin and lonBin values to match across datasets\n",
    "# Run this once and save output, it takes a while (22ish mins)\n",
    "# TODO this is not true\n",
    "\n",
    "# from collections import defaultdict\n",
    "\n",
    "# third_data[\"latBin\"] = 0\n",
    "# third_data[\"lonBin\"] = 0\n",
    "# binValues = sorted(list(dict.fromkeys(list(zip(second_data['latBin'], second_data['lonBin'])))))\n",
    "# len(binValues)\n",
    "# len(second_data['latBin'].unique())\n",
    "# len(second_data['lonBin'].unique())\n",
    "\n",
    "\n",
    "# for latBinValue, lonBinValue in binValues:\n",
    "#     third_data.loc[third_data['latitude'] >= latBinValue, ['latBin']] = latBinValue\n",
    "#     third_data.loc[third_data['longitude'] >= lonBinValue, ['lonBin']] = lonBinValue\n",
    "\n",
    "# binValues = dict.fromkeys(list(second_data['latBin'].unique()))\n",
    "# binValues = defaultdict(list)\n",
    "\n",
    "# for k, v in list(zip(second_data['latBin'], second_data['lonBin'])):\n",
    "#     if v not in binValues[k]:\n",
    "#         binValues[k].append(v)\n",
    "\n",
    "# binValues.keys()\n",
    "# for latBinValue in sorted(binValues.keys()):\n",
    "#     third_data.loc[third_data['latitude'] >= latBinValue, ['latBin']] = latBinValue\n",
    "#     for lonBinValue in sorted(binValues[latBinValue]):\n",
    "#         third_data.loc[(third_data['latBin'] == latBinValue) & (third_data['longitude'] <= lonBinValue), ['lonBin']] = lonBinValue # \"less than\" bc the values are negative\n",
    "\n",
    "# for lonBinValue in sorted(second_data['lonBin'].unique()):\n",
    "#     third_data.loc[third_data['longitude'] >= lonBinValue, ['lonBin']] = lonBinValue\n",
    "\n",
    "#TODO do the min euclidean distance\n",
    "# third_data.loc[third_data['latitude'] >= latBinValue\n",
    "\n",
    "# third_data"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Save the processed dataframes so we don't have to compute lat and long bins every time\n",
    "# TODO not true anymore\n",
    "third_data.to_csv('../data/2015_data.csv')\n",
    "# first_data.to_csv('../data/1995_data.csv')"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.7",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.7 64-bit ('climate': conda)"
  },
  "interpreter": {
   "hash": "861821414808db1f617223c6d4569b19cc725b2a2a07694c74cd2c6384ef391b"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}