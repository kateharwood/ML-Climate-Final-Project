{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from collections import Counter\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "data = pd.read_csv('data/parsed_data.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Prepare Data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# Encode tree species as their frequency count rather than one hot encoding, since there are 100s of speicies\n",
    "# Loss of info, but it's a tradeoff\n",
    "data.spc_latin = data.spc_latin.map(data.spc_latin.value_counts()) "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "# Encode borough as number\n",
    "borough_dict = {\"Manhattan\":1, \"Brooklyn\": 2, \"Queens\": 3, \"Bronx\":4, \"Staten Island\": 5}\n",
    "# data.borough = data.borough.map(borough_dict) \n",
    "data[\"borough\"] = data[\"borough\"].map(borough_dict)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "data"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>borough</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>spc_latin</th>\n",
       "      <th>tree_diameter</th>\n",
       "      <th>wires</th>\n",
       "      <th>sidew_crack_raise</th>\n",
       "      <th>latBin</th>\n",
       "      <th>lonBin</th>\n",
       "      <th>lonDistance</th>\n",
       "      <th>latDistance</th>\n",
       "      <th>avg_health_round</th>\n",
       "      <th>avg_health</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10001</td>\n",
       "      <td>86428</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40.7485</td>\n",
       "      <td>-73.9855</td>\n",
       "      <td>5.730000e-04</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10001</td>\n",
       "      <td>10486</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40.7485</td>\n",
       "      <td>-73.9855</td>\n",
       "      <td>1.920000e-04</td>\n",
       "      <td>0.000247</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10001</td>\n",
       "      <td>86428</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40.7485</td>\n",
       "      <td>-73.9855</td>\n",
       "      <td>8.910000e-04</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10001</td>\n",
       "      <td>86428</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40.7485</td>\n",
       "      <td>-73.9855</td>\n",
       "      <td>8.910000e-04</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10001</td>\n",
       "      <td>86428</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40.7485</td>\n",
       "      <td>-73.9855</td>\n",
       "      <td>8.910000e-04</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008854</th>\n",
       "      <td>544364</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11694</td>\n",
       "      <td>161433</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>40.5810</td>\n",
       "      <td>-73.8530</td>\n",
       "      <td>1.771800e-04</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008855</th>\n",
       "      <td>544365</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11694</td>\n",
       "      <td>169398</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>40.5790</td>\n",
       "      <td>-73.8455</td>\n",
       "      <td>8.304000e-05</td>\n",
       "      <td>0.000279</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.454545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008856</th>\n",
       "      <td>544366</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11694</td>\n",
       "      <td>169398</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>40.5790</td>\n",
       "      <td>-73.8455</td>\n",
       "      <td>8.304000e-05</td>\n",
       "      <td>0.000279</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.454545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008857</th>\n",
       "      <td>544367</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11694</td>\n",
       "      <td>169398</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>40.5790</td>\n",
       "      <td>-73.8455</td>\n",
       "      <td>8.304000e-05</td>\n",
       "      <td>0.000279</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.454545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008858</th>\n",
       "      <td>544368</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11694</td>\n",
       "      <td>161433</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>40.5790</td>\n",
       "      <td>-73.8530</td>\n",
       "      <td>9.999999e-08</td>\n",
       "      <td>0.000193</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.833333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1008859 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0  borough  zipcode  spc_latin  tree_diameter  wires  \\\n",
       "0                 0      1.0    10001      86428              4      0   \n",
       "1                 1      1.0    10001      10486             10      0   \n",
       "2                 2      1.0    10001      86428              4      0   \n",
       "3                 3      1.0    10001      86428              4      0   \n",
       "4                 4      1.0    10001      86428              3      0   \n",
       "...             ...      ...      ...        ...            ...    ...   \n",
       "1008854      544364      3.0    11694     161433             16      0   \n",
       "1008855      544365      3.0    11694     169398             11      1   \n",
       "1008856      544366      3.0    11694     169398             14      1   \n",
       "1008857      544367      3.0    11694     169398             14      1   \n",
       "1008858      544368      3.0    11694     161433             10      1   \n",
       "\n",
       "         sidew_crack_raise   latBin   lonBin   lonDistance  latDistance  \\\n",
       "0                        0  40.7485 -73.9855  5.730000e-04     0.000090   \n",
       "1                        0  40.7485 -73.9855  1.920000e-04     0.000247   \n",
       "2                        0  40.7485 -73.9855  8.910000e-04     0.000042   \n",
       "3                        0  40.7485 -73.9855  8.910000e-04     0.000042   \n",
       "4                        0  40.7485 -73.9855  8.910000e-04     0.000042   \n",
       "...                    ...      ...      ...           ...          ...   \n",
       "1008854                  1  40.5810 -73.8530  1.771800e-04     0.000005   \n",
       "1008855                  1  40.5790 -73.8455  8.304000e-05     0.000279   \n",
       "1008856                  1  40.5790 -73.8455  8.304000e-05     0.000279   \n",
       "1008857                  0  40.5790 -73.8455  8.304000e-05     0.000279   \n",
       "1008858                  0  40.5790 -73.8530  9.999999e-08     0.000193   \n",
       "\n",
       "         avg_health_round  avg_health  \n",
       "0                     3.0    3.000000  \n",
       "1                     3.0    3.000000  \n",
       "2                     3.0    3.000000  \n",
       "3                     3.0    3.000000  \n",
       "4                     3.0    3.000000  \n",
       "...                   ...         ...  \n",
       "1008854               3.0    3.000000  \n",
       "1008855               2.0    2.454545  \n",
       "1008856               2.0    2.454545  \n",
       "1008857               2.0    2.454545  \n",
       "1008858               3.0    2.833333  \n",
       "\n",
       "[1008859 rows x 13 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "# Scale/Standardize data\n",
    "# TODO don't need to normalize the categorical data\n",
    "# TODO do we even need this? just one col is actually continuous that we are using in the end (tree diameter)\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# scaler = StandardScaler()\n",
    "# scaler.fit(data) \n",
    "# data_scaled = pd.DataFrame(scaler.transform(data),columns = ??? )\n",
    "# data_scaled"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data[['zipcode', 'spc_latin', 'tree_diameter', 'latBin', 'lonBin', 'wires', 'sidew_crack_raise']], data.avg_health_round, test_size=0.20, random_state=0)\n",
    "print(X_train)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "        zipcode  spc_latin  tree_diameter   latBin   lonBin  wires  \\\n",
      "458540    11435     169398             16  40.6860 -73.8040      0   \n",
      "756669    11226      86428              9  40.6495 -73.9495      0   \n",
      "700308    11209        637              1  40.6270 -74.0240      0   \n",
      "570760    10312      86428              4  40.5295 -74.1625      1   \n",
      "530301    10306       1682              8  40.5740 -74.1215      0   \n",
      "...         ...        ...            ...      ...      ...    ...   \n",
      "963395    11422      15669              3  40.6510 -73.7295      1   \n",
      "117952    10456      86428              3  40.8285 -73.9045      0   \n",
      "435829    11427      86428              7  40.7305 -73.7435      0   \n",
      "305711    11358     169398             22  40.7570 -73.7910      1   \n",
      "985772    11433       5688              6  40.6940 -73.7870      0   \n",
      "\n",
      "        sidew_crack_raise  \n",
      "458540                  0  \n",
      "756669                  1  \n",
      "700308                  0  \n",
      "570760                  0  \n",
      "530301                  0  \n",
      "...                   ...  \n",
      "963395                  0  \n",
      "117952                  0  \n",
      "435829                  0  \n",
      "305711                  0  \n",
      "985772                  0  \n",
      "\n",
      "[807087 rows x 7 columns]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "# Check how unbalanced dataset is\n",
    "# data.avg_health.value_counts()\n",
    "# data.avg_health_round.value_counts()\n",
    "print(Counter(y_train))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Counter({2.0: 413649, 3.0: 370013, 1.0: 21089, 0.0: 2336})\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "# Try random oversampling\n",
    "ros = RandomOverSampler()\n",
    "X_train, y_train = ros.fit_resample(X_train, y_train)\n",
    "print(Counter(y_train))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Counter({2.0: 413649, 3.0: 413649, 0.0: 413649, 1.0: 413649})\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "# Try random undersampling (this performed worse)\n",
    "# rus = RandomUnderSampler()\n",
    "# X_train, y_train = rus.fit_resample(X_train, y_train)\n",
    "# print(Counter(y_train))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Counter({0.0: 2336, 1.0: 2336, 2.0: 2336, 3.0: 2336})\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Classification\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train, y_train)\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "metadata": {},
     "execution_count": 126
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "source": [
    "predictions = log_reg.predict(X_test)\n",
    "# print(sklearn.metrics.classification_report(predictions, y_test))\n",
    "# print(\"Accuracy\")\n",
    "# print(log_reg.score(X_test, y_test))\n",
    "\n",
    "# print(\"F1 Macro\")\n",
    "# print(sklearn.metrics.f1_score(predictions, y_test, average='macro'))\n",
    "\n",
    "# print(\"F1 weighted: \") \n",
    "# print(sklearn.metrics.f1_score(predictions, y_test, average='weighted'))\n",
    "\n",
    "# print('Precision per class')\n",
    "# print(sklearn.metrics.precision_score(predictions, y_test, average=None))\n",
    "\n",
    "# print('Recall per class')\n",
    "# print(sklearn.metrics.recall_score(predictions, y_test, average=None))\n",
    "\n",
    "# precision, recall, fscore, support = sklearn.metrics.precision_recall_fscore_support(y_test, predictions)\n",
    "# print('precision: {}'.format(precision))\n",
    "# print('recall: {}'.format(recall))\n",
    "# print('fscore: {}'.format(fscore))\n",
    "# print('support: {}'.format(support))\n",
    "\n",
    "report = sklearn.metrics.classification_report(y_test, predictions)\n",
    "print(report)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/kateharwood/opt/miniconda3/envs/climate/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/kateharwood/opt/miniconda3/envs/climate/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.60      0.01       603\n",
      "         1.0       0.02      0.11      0.04      5173\n",
      "         2.0       0.56      0.36      0.43    103354\n",
      "         3.0       0.00      0.00      0.00     92642\n",
      "\n",
      "    accuracy                           0.19    201772\n",
      "   macro avg       0.15      0.27      0.12    201772\n",
      "weighted avg       0.29      0.19      0.22    201772\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/kateharwood/opt/miniconda3/envs/climate/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "source": [
    "# Feature influence\n",
    "print('Feature influence')\n",
    "print(log_reg.coef_)\n",
    "# print(np.std(X_train, 0)*log_ref.coef_)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Feature influence\n",
      "[[ 8.93830071e-06 -1.19162890e-06  1.49081186e-08  3.18664141e-08\n",
      "  -5.73179965e-08  7.92462037e-10  7.17089123e-10]\n",
      " [-6.62261236e-06  8.94516213e-07 -2.36067606e-08 -2.48173762e-08\n",
      "   4.52883483e-08 -8.40244077e-10 -1.26547880e-09]\n",
      " [-6.92264075e-06  9.25343723e-07 -1.69611846e-08 -2.53794632e-08\n",
      "   4.57695693e-08 -6.67470916e-10 -1.01184263e-09]\n",
      " [ 4.60695241e-06 -6.28231035e-07  2.56598265e-08  1.83304253e-08\n",
      "  -3.37399210e-08  7.15252955e-10  1.56023230e-09]]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "random_forest=RandomForestClassifier(n_estimators=500)\n",
    "random_forest.fit(X_train,y_train)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=500)"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "# Eval\n",
    "predictions = random_forest.predict(X_test)\n",
    "\n",
    "# print(\"Accuracy\")\n",
    "# print(random_forest.score(X_test, y_test))\n",
    "\n",
    "# print(\"F1 Macro\")\n",
    "# print(sklearn.metrics.f1_score(y_test, predictions,average='macro'))\n",
    "\n",
    "# print(\"F1 weighted: \") \n",
    "# print(sklearn.metrics.f1_score(y_test, predictions, average='weighted'))\n",
    "\n",
    "# print('Precision per class')\n",
    "# print(sklearn.metrics.precision_score(y_test, predictions, average=None))\n",
    "\n",
    "# print('Recall per class')\n",
    "# print(sklearn.metrics.recall_score(y_test, predictions, average=None))\n",
    "\n",
    "report = sklearn.metrics.classification_report(y_test, predictions)\n",
    "print(report)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.46      0.60       603\n",
      "         1.0       0.73      0.55      0.63      5173\n",
      "         2.0       0.80      0.80      0.80    103354\n",
      "         3.0       0.78      0.79      0.78     92642\n",
      "\n",
      "    accuracy                           0.79    201772\n",
      "   macro avg       0.79      0.65      0.70    201772\n",
      "weighted avg       0.79      0.79      0.79    201772\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "source": [
    "# Grid search cross validation\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'n_estimators': [100,500,1000], 'criterion': ['entropy', 'gini']}\n",
    "\n",
    "grid_clf = GridSearchCV(random_forest, param_grid, scoring=['f1_weighted', 'f1_macro','accuracy'], refit='accuracy', cv=3)\n",
    "grid_clf.fit(X_train, y_train)\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=RandomForestClassifier(criterion='entropy',\n",
       "                                              n_estimators=50),\n",
       "             param_grid={'criterion': ['entropy', 'gini'],\n",
       "                         'n_estimators': [100, 500, 1000]},\n",
       "             refit='accuracy', scoring=['f1_weighted', 'f1_macro', 'accuracy'])"
      ]
     },
     "metadata": {},
     "execution_count": 93
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "source": [
    "# Hyperparam grid search results and eval\n",
    "grid_clf.cv_results_\n",
    "grid_clf.best_estimator_\n",
    "grid_clf.best_score_\n",
    "\n",
    "import pickle\n",
    "filename = 'grid_clf.best_estimator_.sav'\n",
    "pickle.dump(grid_clf.best_estimator_, open(filename, 'wb'))\n",
    "\n",
    "# predictions = grid_clf.best_estimator_.predict(X_train)\n",
    "# predictions = random_forest.predict(X_train)\n",
    "# # report = sklearn.metrics.classification_report(y_test, predictions)\n",
    "# # print(report)\n",
    "# grid_clf.best_estimator_.score(X_test, y_test)\n",
    "# sklearn.metrics.accuracy_score(y_test, predictions)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "source": [
    "# Feature influence\n",
    "# From sklearn: The higher, the more important the feature. \n",
    "# The importance of a feature is computed as the (normalized) total reduction of the criterion brought by that feature. \n",
    "# It is also known as the Gini importance.\n",
    "\n",
    "# This shows that lat and lon bin are the most important\n",
    "# Zip code and species are least important\n",
    "random_forest.feature_importances_"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0.05849014, 0.09828617, 0.15330729, 0.33727531, 0.35264109])"
      ]
     },
     "metadata": {},
     "execution_count": 132
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Regression\n",
    "### (This did not work well)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data[['zipcode', 'spc_latin', 'tree_diameter', 'latBin', 'lonBin']], data.avg_health, test_size=0.20, random_state=0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lin_reg = LinearRegression(fit_intercept=True)\n",
    "lin_reg.fit(X_train, y_train)\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "metadata": {},
     "execution_count": 128
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "source": [
    "predictions = lin_reg.predict(X_test)\n",
    "print(\"Score\")\n",
    "print(lin_reg.score(X_test, y_test))\n",
    "\n",
    "print('Feature influence')\n",
    "print(lin_reg.coef_)\n",
    "print(np.std(X_train, 0)*lin_reg.coef_)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Score\n",
      "0.011350976452213057\n",
      "Feature influence\n",
      "[ 2.14129907e-05 -5.64659458e-07  4.75334829e-03  1.82898365e-01\n",
      " -3.07816016e-01]\n",
      "zipcode          0.010920\n",
      "spc_latin       -0.035764\n",
      "tree_diameter    0.045405\n",
      "latBin           0.016108\n",
      "lonBin          -0.039221\n",
      "dtype: float64\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "random_forest_reg=RandomForestRegressor(n_estimators=100)\n",
    "random_forest_reg.fit(X_train,y_train)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "RandomForestRegressor()"
      ]
     },
     "metadata": {},
     "execution_count": 93
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "source": [
    "print(\"Score\")\n",
    "random_forest_reg.score(X_test, y_test)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Score\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.4181915364123192"
      ]
     },
     "metadata": {},
     "execution_count": 109
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.7",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.7 64-bit ('climate': conda)"
  },
  "interpreter": {
   "hash": "861821414808db1f617223c6d4569b19cc725b2a2a07694c74cd2c6384ef391b"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}