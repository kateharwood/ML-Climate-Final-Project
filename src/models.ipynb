{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can run with either the tree data or the tree data plus PLUTO data\n",
    "# data = pd.read_csv('data/parsed_data.csv')\n",
    "data = pd.read_csv('data/parsed_pluto_tree_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode tree species as their frequency count rather than one hot encoding, since there are 100s of species\n",
    "# Loss of info, but it's a tradeoff\n",
    "data.spc_latin = data.spc_latin.map(data.spc_latin.value_counts()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode borough as number\n",
    "borough_dict = {\"Manhattan\":1, \"Brooklyn\": 2, \"Queens\": 3, \"Bronx\":4, \"Staten Island\": 5}\n",
    "# data.borough = data.borough.map(borough_dict) \n",
    "data[\"borough\"] = data[\"borough\"].map(borough_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>borough</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>spc_latin</th>\n",
       "      <th>tree_diameter</th>\n",
       "      <th>wires</th>\n",
       "      <th>sidew_crack_raise</th>\n",
       "      <th>latBin</th>\n",
       "      <th>lonBin</th>\n",
       "      <th>lonDistance</th>\n",
       "      <th>latDistance</th>\n",
       "      <th>avg_health_round</th>\n",
       "      <th>avg_health</th>\n",
       "      <th>landuseavg</th>\n",
       "      <th>numfloorsavg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>40.748590</td>\n",
       "      <td>-73.984927</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10001</td>\n",
       "      <td>470</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40.7485</td>\n",
       "      <td>-73.9855</td>\n",
       "      <td>0.000573</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>40.748835</td>\n",
       "      <td>-73.985520</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10001</td>\n",
       "      <td>46</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40.7485</td>\n",
       "      <td>-73.9855</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000335</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>40.748854</td>\n",
       "      <td>-73.985564</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10001</td>\n",
       "      <td>683</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40.7485</td>\n",
       "      <td>-73.9855</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>0.000354</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>40.748801</td>\n",
       "      <td>-73.985436</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10001</td>\n",
       "      <td>470</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40.7485</td>\n",
       "      <td>-73.9855</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>0.000301</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>40.748835</td>\n",
       "      <td>-73.985520</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10001</td>\n",
       "      <td>470</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40.7485</td>\n",
       "      <td>-73.9855</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000335</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3087</th>\n",
       "      <td>3087</td>\n",
       "      <td>40.728631</td>\n",
       "      <td>-73.851211</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11375</td>\n",
       "      <td>32</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40.7285</td>\n",
       "      <td>-73.8515</td>\n",
       "      <td>0.000289</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3088</th>\n",
       "      <td>3088</td>\n",
       "      <td>40.728506</td>\n",
       "      <td>-73.851632</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11375</td>\n",
       "      <td>57</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40.7285</td>\n",
       "      <td>-73.8515</td>\n",
       "      <td>0.000132</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3089</th>\n",
       "      <td>3089</td>\n",
       "      <td>40.728506</td>\n",
       "      <td>-73.851632</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11375</td>\n",
       "      <td>57</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40.7285</td>\n",
       "      <td>-73.8515</td>\n",
       "      <td>0.000132</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3090</th>\n",
       "      <td>3090</td>\n",
       "      <td>40.728506</td>\n",
       "      <td>-73.851632</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11375</td>\n",
       "      <td>57</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40.7285</td>\n",
       "      <td>-73.8515</td>\n",
       "      <td>0.000132</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3091</th>\n",
       "      <td>3091</td>\n",
       "      <td>40.728556</td>\n",
       "      <td>-73.851464</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11375</td>\n",
       "      <td>470</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40.7285</td>\n",
       "      <td>-73.8515</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3092 rows Ã— 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0   latitude  longitude  borough  zipcode  spc_latin  \\\n",
       "0              0  40.748590 -73.984927      1.0    10001        470   \n",
       "1              1  40.748835 -73.985520      1.0    10001         46   \n",
       "2              2  40.748854 -73.985564      1.0    10001        683   \n",
       "3              3  40.748801 -73.985436      1.0    10001        470   \n",
       "4              4  40.748835 -73.985520      1.0    10001        470   \n",
       "...          ...        ...        ...      ...      ...        ...   \n",
       "3087        3087  40.728631 -73.851211      3.0    11375         32   \n",
       "3088        3088  40.728506 -73.851632      3.0    11375         57   \n",
       "3089        3089  40.728506 -73.851632      3.0    11375         57   \n",
       "3090        3090  40.728506 -73.851632      3.0    11375         57   \n",
       "3091        3091  40.728556 -73.851464      3.0    11375        470   \n",
       "\n",
       "      tree_diameter  wires  sidew_crack_raise   latBin   lonBin  lonDistance  \\\n",
       "0                 4      0                  0  40.7485 -73.9855     0.000573   \n",
       "1                 3      0                  0  40.7485 -73.9855     0.000020   \n",
       "2                 5      0                  0  40.7485 -73.9855     0.000064   \n",
       "3                 4      0                  0  40.7485 -73.9855     0.000064   \n",
       "4                 3      0                  0  40.7485 -73.9855     0.000020   \n",
       "...             ...    ...                ...      ...      ...          ...   \n",
       "3087             17      0                  0  40.7285 -73.8515     0.000289   \n",
       "3088              4      0                  0  40.7285 -73.8515     0.000132   \n",
       "3089              2      0                  0  40.7285 -73.8515     0.000132   \n",
       "3090              2      0                  0  40.7285 -73.8515     0.000132   \n",
       "3091              4      0                  0  40.7285 -73.8515     0.000036   \n",
       "\n",
       "      latDistance  avg_health_round  avg_health  landuseavg  numfloorsavg  \n",
       "0        0.000090               3.0         3.0         5.0          34.0  \n",
       "1        0.000335               3.0         3.0         5.0          34.0  \n",
       "2        0.000354               3.0         3.0         5.0          34.0  \n",
       "3        0.000301               3.0         3.0         5.0          34.0  \n",
       "4        0.000335               3.0         3.0         5.0          34.0  \n",
       "...           ...               ...         ...         ...           ...  \n",
       "3087     0.000131               2.0         2.0         6.0          20.0  \n",
       "3088     0.000006               2.0         2.0         6.0          20.0  \n",
       "3089     0.000006               2.0         2.0         6.0          20.0  \n",
       "3090     0.000006               2.0         2.0         6.0          20.0  \n",
       "3091     0.000056               2.0         2.0         6.0          20.0  \n",
       "\n",
       "[3092 rows x 17 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4  3  5 11 10 15 17 16  6 14 13  0  7  2 12 18 19  8 20  1  9 24 26 22\n",
      " 23 28 25 27 33 39 43 41 21 29 40 36 32 34 31 35]\n",
      "40\n",
      "[470  46 683  57 420   2  32  40 204  16  26  59  25  69  24 113   3 299\n",
      "   9  15   7  36   5  11   6  58  37  12  63  18  17  10   1  13   4   8]\n",
      "36\n",
      "[0 1]\n",
      "2\n",
      "[0 1]\n",
      "2\n",
      "[0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 44.0, 45.0, 46.0, 47.0, 49.0, 50.0, 51.0, 57.0, 60.0]\n",
      "52\n",
      "[ 5.  3.  8.  6.  2.  4.  7. 10.  9.  1. 11.]\n",
      "11\n",
      "109\n"
     ]
    }
   ],
   "source": [
    "# Num unique features\n",
    "print(data['tree_diameter'].unique())\n",
    "print(len(data['tree_diameter'].unique()))\n",
    "\n",
    "print(data['spc_latin'].unique())\n",
    "print(len(data['spc_latin'].unique()))\n",
    "\n",
    "print(data['wires'].unique())\n",
    "print(len(data['wires'].unique()))\n",
    "\n",
    "print(data['sidew_crack_raise'].unique())\n",
    "print(len(data['sidew_crack_raise'].unique()))\n",
    "\n",
    "print(sorted(data['numfloorsavg'].unique()))\n",
    "print(len(data['numfloorsavg'].unique()))\n",
    "\n",
    "print(data['landuseavg'].unique())\n",
    "print(len(data['landuseavg'].unique()))\n",
    "\n",
    "print(len(data['latBin'].unique()))\n",
    "print(len(data['lonBin'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Was using this when thinking about using more continuous data, but ended up using basically all categorical data\n",
    "\n",
    "# Scale/Standardize data\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# scaler = StandardScaler()\n",
    "# scaler.fit(data) \n",
    "# data_scaled = pd.DataFrame(scaler.transform(data),columns =  )\n",
    "# data_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      zipcode  spc_latin  tree_diameter   latBin   lonBin  wires  \\\n",
      "2708    10023        470              6  40.7715 -73.9850      0   \n",
      "2077    10016        113             10  40.7445 -73.9800      0   \n",
      "1564    10010        683              3  40.7355 -73.9765      0   \n",
      "411     10001        470              8  40.7500 -73.9965      0   \n",
      "2437    10021        683             10  40.7675 -73.9535      0   \n",
      "...       ...        ...            ...      ...      ...    ...   \n",
      "763     10002         69              5  40.7170 -73.9885      0   \n",
      "835     10003         24              6  40.7340 -73.9890      0   \n",
      "1653    10011        113              5  40.7335 -73.9955      0   \n",
      "2607    10023         59             14  40.7735 -73.9815      0   \n",
      "2732    10025        299              5  40.8045 -73.9630      0   \n",
      "\n",
      "      sidew_crack_raise  landuseavg  numfloorsavg  \n",
      "2708                  0         7.0          19.0  \n",
      "2077                  0         4.0          31.0  \n",
      "1564                  0         4.0          15.0  \n",
      "411                   0         2.0           6.0  \n",
      "2437                  0         3.0          37.0  \n",
      "...                 ...         ...           ...  \n",
      "763                   0         3.0          23.0  \n",
      "835                   0         6.0          18.0  \n",
      "1653                  0         8.0           1.0  \n",
      "2607                  0         6.0          23.0  \n",
      "2732                  0         8.0          15.0  \n",
      "\n",
      "[2473 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "# Choose which features to use when running the models\n",
    "X_train, X_test, y_train, y_test = train_test_split(data[['zipcode', 'spc_latin', 'tree_diameter', 'latBin', 'lonBin', 'wires', 'sidew_crack_raise', 'landuseavg', 'numfloorsavg']], data.avg_health_round, test_size=0.20, random_state=0)\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({2.0: 1447, 3.0: 918, 1.0: 102, 0.0: 6})\n"
     ]
    }
   ],
   "source": [
    "# Check how unbalanced dataset is\n",
    "# data.avg_health.value_counts()\n",
    "# data.avg_health_round.value_counts()\n",
    "print(Counter(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({2.0: 1447, 3.0: 1447, 1.0: 1447, 0.0: 1447})\n"
     ]
    }
   ],
   "source": [
    "# Try random oversampling\n",
    "ros = RandomOverSampler()\n",
    "X_train, y_train = ros.fit_resample(X_train, y_train)\n",
    "print(Counter(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0.0: 2336, 1.0: 2336, 2.0: 2336, 3.0: 2336})\n"
     ]
    }
   ],
   "source": [
    "# Try random undersampling (this performed worse)\n",
    "# rus = RandomUnderSampler()\n",
    "# X_train, y_train = rus.fit_resample(X_train, y_train)\n",
    "# print(Counter(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kateharwood/opt/miniconda3/envs/climate/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kateharwood/opt/miniconda3/envs/climate/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/kateharwood/opt/miniconda3/envs/climate/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.60      0.01       603\n",
      "         1.0       0.02      0.11      0.04      5173\n",
      "         2.0       0.56      0.36      0.43    103354\n",
      "         3.0       0.00      0.00      0.00     92642\n",
      "\n",
      "    accuracy                           0.19    201772\n",
      "   macro avg       0.15      0.27      0.12    201772\n",
      "weighted avg       0.29      0.19      0.22    201772\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kateharwood/opt/miniconda3/envs/climate/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "predictions = log_reg.predict(X_test)\n",
    "report = sklearn.metrics.classification_report(y_test, predictions)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature influence\n",
      "[[ 8.93830071e-06 -1.19162890e-06  1.49081186e-08  3.18664141e-08\n",
      "  -5.73179965e-08  7.92462037e-10  7.17089123e-10]\n",
      " [-6.62261236e-06  8.94516213e-07 -2.36067606e-08 -2.48173762e-08\n",
      "   4.52883483e-08 -8.40244077e-10 -1.26547880e-09]\n",
      " [-6.92264075e-06  9.25343723e-07 -1.69611846e-08 -2.53794632e-08\n",
      "   4.57695693e-08 -6.67470916e-10 -1.01184263e-09]\n",
      " [ 4.60695241e-06 -6.28231035e-07  2.56598265e-08  1.83304253e-08\n",
      "  -3.37399210e-08  7.15252955e-10  1.56023230e-09]]\n"
     ]
    }
   ],
   "source": [
    "# Feature influence\n",
    "print('Feature influence')\n",
    "print(log_reg.coef_)\n",
    "# print(np.std(X_train, 0)*log_ref.coef_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "random_forest=RandomForestClassifier(n_estimators=1000)\n",
    "random_forest.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.94      0.85      0.89        20\n",
      "         2.0       0.93      0.94      0.94       363\n",
      "         3.0       0.92      0.90      0.91       236\n",
      "\n",
      "    accuracy                           0.93       619\n",
      "   macro avg       0.93      0.90      0.91       619\n",
      "weighted avg       0.93      0.93      0.93       619\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Eval\n",
    "predictions = random_forest.predict(X_test)\n",
    "report = sklearn.metrics.classification_report(y_test, predictions)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=RandomForestClassifier(criterion='entropy',\n",
       "                                              n_estimators=50),\n",
       "             param_grid={'criterion': ['entropy', 'gini'],\n",
       "                         'n_estimators': [100, 500, 1000]},\n",
       "             refit='accuracy', scoring=['f1_weighted', 'f1_macro', 'accuracy'])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grid search cross validation\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# param_grid = {'n_estimators': [100,500,1000], 'criterion': ['entropy', 'gini']}\n",
    "\n",
    "# grid_clf = GridSearchCV(random_forest, param_grid, scoring=['f1_weighted', 'f1_macro','accuracy'], refit='accuracy', cv=3)\n",
    "# grid_clf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparam grid search results and eval\n",
    "# grid_clf.cv_results_\n",
    "# grid_clf.best_estimator_\n",
    "# grid_clf.best_score_\n",
    "\n",
    "# import pickle\n",
    "# filename = 'grid_clf.best_estimator_.sav'\n",
    "# pickle.dump(grid_clf.best_estimator_, open(filename, 'wb'))\n",
    "\n",
    "# predictions = grid_clf.best_estimator_.predict(X_train)\n",
    "# predictions = random_forest.predict(X_train)\n",
    "# # report = sklearn.metrics.classification_report(y_test, predictions)\n",
    "# # print(report)\n",
    "# grid_clf.best_estimator_.score(X_test, y_test)\n",
    "# sklearn.metrics.accuracy_score(y_test, predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.15157782, 0.12423122, 0.07510414, 0.20895941, 0.14897492,\n",
       "       0.00340121, 0.01158761, 0.08171396, 0.19444972])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature influence\n",
    "# From sklearn: The higher, the more important the feature. \n",
    "# The importance of a feature is computed as the (normalized) total reduction of the criterion brought by that feature. \n",
    "# It is also known as the Gini importance.\n",
    "\n",
    "random_forest.feature_importances_\n",
    "\n",
    "#From first features: array([0.05849014, 0.09828617, 0.15330729, 0.33727531, 0.35264109])\n",
    "# This shows that lat and lon bin are the most important\n",
    "# Zip code and species are least important\n",
    "\n",
    "\n",
    "#With PLUTO data: array([0.14133116, 0.12636846, 0.08450248, 0.20923166, 0.16384807, 0.0844982 , 0.19021996])\n",
    "#In order of importance: latbin, numfloors, lonbin, zipcode, spc, landuse, diameter\n",
    "\n",
    "#With PLUTO data and wires and sidewalk: \n",
    "# array([0.14362981, 0.12422975, 0.07294823, 0.22162114, 0.14892171, 0.00399293, 0.01116889, 0.08029825, 0.19318929])\n",
    "# In order of importance: lat, numfloors, lon, zipcode, spc, landuse, diameter, sidewalk, wires\n",
    "# With 1000 trees: array([0.14992811, 0.12930077, 0.07363184, 0.20934803, 0.15155635, 0.00338376, 0.01061805, 0.08095947, 0.19127362])\n",
    "# lat, numfloors, lon, zipcode, spc, landuse, diam, sidewalk, wires\n",
    "\n",
    "# Same as above but without lat and lon bin:\n",
    "#array([0.26028929, 0.16251933, 0.1134749 , 0.00598594, 0.01296771, 0.1436791 , 0.30108372])\n",
    "# numfloors, zipcode, landuse, spc, diam, sidewalk, wires\n",
    "\n",
    "# Same as above but without zipcode either:\n",
    "# array([0.1993551 , 0.14890345, 0.00593354, 0.01365038, 0.20375706, 0.42840046])\n",
    "# numfloors, landuse, spc, diameter, sidewalks, wires\n",
    "\n",
    "# array([0.4826821 , 0.45951688, 0.02285163, 0.0349494 ]) spc, diam, sidewalk, wires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(learning_rate=1.0, max_depth=8, n_estimators=500,\n",
       "                           random_state=0)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gradient Boosting\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gradient_boosting = GradientBoostingClassifier(n_estimators=500, learning_rate=1.0, max_depth=8, random_state=0)\n",
    "gradient_boosting.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search cross validation\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# param_grid = {'n_estimators': [100,500,1000], 'learning_rate': [0.001, 0.01, 0.1, 0.2]}\n",
    "\n",
    "# grid_clf = GridSearchCV(gradient_boosting, param_grid, scoring=['f1_weighted', 'f1_macro','accuracy'], refit='accuracy', cv=3)\n",
    "# grid_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.94      0.85      0.89        20\n",
      "         2.0       0.94      0.96      0.95       363\n",
      "         3.0       0.94      0.91      0.92       236\n",
      "\n",
      "    accuracy                           0.94       619\n",
      "   macro avg       0.94      0.91      0.92       619\n",
      "weighted avg       0.94      0.94      0.94       619\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Eval\n",
    "predictions = gradient_boosting.predict(X_test)\n",
    "report = sklearn.metrics.classification_report(y_test, predictions)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=3, cache_size=500, gamma='auto', random_state=0)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SVM\n",
    "from sklearn.svm import SVC\n",
    "svm = SVC(gamma='auto', C=3, random_state=0)\n",
    "svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       0.88      0.75      0.81        20\n",
      "         2.0       0.88      0.92      0.90       363\n",
      "         3.0       0.88      0.82      0.85       236\n",
      "\n",
      "    accuracy                           0.88       619\n",
      "   macro avg       0.66      0.62      0.64       619\n",
      "weighted avg       0.88      0.88      0.88       619\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kateharwood/opt/miniconda3/envs/climate/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/kateharwood/opt/miniconda3/envs/climate/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/kateharwood/opt/miniconda3/envs/climate/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Eval\n",
    "predictions = svm.predict(X_test)\n",
    "report = sklearn.metrics.classification_report(y_test, predictions)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression\n",
    "### (This did not work well)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data[['zipcode', 'spc_latin', 'tree_diameter', 'latBin', 'lonBin']], data.avg_health, test_size=0.20, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lin_reg = LinearRegression(fit_intercept=True)\n",
    "lin_reg.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score\n",
      "0.011350976452213057\n",
      "Feature influence\n",
      "[ 2.14129907e-05 -5.64659458e-07  4.75334829e-03  1.82898365e-01\n",
      " -3.07816016e-01]\n",
      "zipcode          0.010920\n",
      "spc_latin       -0.035764\n",
      "tree_diameter    0.045405\n",
      "latBin           0.016108\n",
      "lonBin          -0.039221\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "predictions = lin_reg.predict(X_test)\n",
    "print(\"Score\")\n",
    "print(lin_reg.score(X_test, y_test))\n",
    "\n",
    "print('Feature influence')\n",
    "print(lin_reg.coef_)\n",
    "print(np.std(X_train, 0)*lin_reg.coef_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor()"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "random_forest_reg=RandomForestRegressor(n_estimators=100)\n",
    "random_forest_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4181915364123192"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Score\")\n",
    "random_forest_reg.score(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation Experiments on Best Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest  0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.96      0.92      0.94        26\n",
      "         2.0       0.92      0.91      0.92       352\n",
      "         3.0       0.88      0.90      0.89       241\n",
      "\n",
      "    accuracy                           0.91       619\n",
      "   macro avg       0.92      0.91      0.92       619\n",
      "weighted avg       0.91      0.91      0.91       619\n",
      "\n",
      "Gradient Boosting  0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      0.88      0.94        26\n",
      "         2.0       0.92      0.93      0.93       352\n",
      "         3.0       0.90      0.89      0.90       241\n",
      "\n",
      "    accuracy                           0.92       619\n",
      "   macro avg       0.94      0.90      0.92       619\n",
      "weighted avg       0.92      0.92      0.92       619\n",
      "\n",
      "Random Forest  1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         1\n",
      "         1.0       0.92      0.86      0.89        28\n",
      "         2.0       0.92      0.94      0.93       359\n",
      "         3.0       0.91      0.90      0.90       231\n",
      "\n",
      "    accuracy                           0.92       619\n",
      "   macro avg       0.94      0.92      0.93       619\n",
      "weighted avg       0.92      0.92      0.92       619\n",
      "\n",
      "Gradient Boosting  1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         1\n",
      "         1.0       0.92      0.86      0.89        28\n",
      "         2.0       0.92      0.94      0.93       359\n",
      "         3.0       0.92      0.89      0.91       231\n",
      "\n",
      "    accuracy                           0.92       619\n",
      "   macro avg       0.94      0.92      0.93       619\n",
      "weighted avg       0.92      0.92      0.92       619\n",
      "\n",
      "Random Forest  2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.33      0.50         3\n",
      "         1.0       0.86      0.75      0.80        24\n",
      "         2.0       0.93      0.92      0.92       361\n",
      "         3.0       0.87      0.91      0.89       231\n",
      "\n",
      "    accuracy                           0.91       619\n",
      "   macro avg       0.92      0.73      0.78       619\n",
      "weighted avg       0.91      0.91      0.91       619\n",
      "\n",
      "Gradient Boosting  2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.33      0.50         3\n",
      "         1.0       0.86      0.79      0.83        24\n",
      "         2.0       0.92      0.91      0.92       361\n",
      "         3.0       0.86      0.90      0.88       231\n",
      "\n",
      "    accuracy                           0.90       619\n",
      "   macro avg       0.91      0.73      0.78       619\n",
      "weighted avg       0.90      0.90      0.90       619\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kateharwood/opt/miniconda3/envs/climate/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/kateharwood/opt/miniconda3/envs/climate/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/kateharwood/opt/miniconda3/envs/climate/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/kateharwood/opt/miniconda3/envs/climate/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/kateharwood/opt/miniconda3/envs/climate/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/kateharwood/opt/miniconda3/envs/climate/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest  3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         1\n",
      "         1.0       0.85      0.96      0.90        24\n",
      "         2.0       0.93      0.93      0.93       359\n",
      "         3.0       0.91      0.89      0.90       235\n",
      "\n",
      "    accuracy                           0.92       619\n",
      "   macro avg       0.67      0.70      0.68       619\n",
      "weighted avg       0.91      0.92      0.92       619\n",
      "\n",
      "Gradient Boosting  3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         1\n",
      "         1.0       0.81      0.88      0.84        24\n",
      "         2.0       0.92      0.92      0.92       359\n",
      "         3.0       0.90      0.89      0.90       235\n",
      "\n",
      "    accuracy                           0.91       619\n",
      "   macro avg       0.66      0.67      0.66       619\n",
      "weighted avg       0.91      0.91      0.91       619\n",
      "\n",
      "Random Forest  4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.91      0.95      0.93        22\n",
      "         2.0       0.95      0.95      0.95       380\n",
      "         3.0       0.91      0.91      0.91       217\n",
      "\n",
      "    accuracy                           0.93       619\n",
      "   macro avg       0.92      0.94      0.93       619\n",
      "weighted avg       0.93      0.93      0.93       619\n",
      "\n",
      "Gradient Boosting  4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.91      0.95      0.93        22\n",
      "         2.0       0.93      0.94      0.93       380\n",
      "         3.0       0.89      0.87      0.88       217\n",
      "\n",
      "    accuracy                           0.91       619\n",
      "   macro avg       0.91      0.92      0.92       619\n",
      "weighted avg       0.91      0.91      0.91       619\n",
      "\n",
      "Accuracy Scores\n",
      "0.9166397415185784\n",
      "0.911470113085622\n",
      "F1 macro scores\n",
      "0.8477809678471171\n",
      "0.8425860736398804\n",
      "F1 Weighted Scores\n",
      "0.9163427277447141\n",
      "0.9111240914720143\n",
      "Standard deviations\n",
      "0.009832067240518884\n",
      "0.0078081072527267014\n",
      "0.10034168095005239\n",
      "0.10479926389334197\n",
      "0.009970767451159034\n",
      "0.007976944158075837\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "ros = RandomOverSampler()\n",
    "\n",
    "rf_accuracies = []\n",
    "gb_accuracies = []\n",
    "rf_f1_macro = []\n",
    "gb_f1_macro = []\n",
    "rf_f1_weighted = []\n",
    "gb_f1_weighted = []\n",
    "\n",
    "# Repeat a different train/test split 5 times to validate best model performance\n",
    "for i in range(5):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data[['zipcode', 'spc_latin', 'tree_diameter', 'latBin', 'lonBin', 'wires', 'sidew_crack_raise', 'landuseavg', 'numfloorsavg']], data.avg_health_round, test_size=0.20, random_state=None)\n",
    "    X_train, y_train = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "    random_forest=RandomForestClassifier(n_estimators=1000)\n",
    "    random_forest.fit(X_train,y_train)\n",
    "\n",
    "    gradient_boosting = GradientBoostingClassifier(n_estimators=1000, learning_rate=0.01, max_depth=10)\n",
    "    gradient_boosting.fit(X_train, y_train)\n",
    "\n",
    "    predictions_rf = random_forest.predict(X_test)\n",
    "    predictions_gb = gradient_boosting.predict(X_test)\n",
    "\n",
    "\n",
    "    report = sklearn.metrics.classification_report(y_test, predictions_rf)\n",
    "    print(\"Random Forest \", i)\n",
    "    print(report)\n",
    "    rf_accuracies.append(sklearn.metrics.accuracy_score(y_test, predictions_rf))\n",
    "    rf_f1_macro.append(sklearn.metrics.f1_score(y_test, predictions_rf, average='macro'))\n",
    "    rf_f1_weighted.append(sklearn.metrics.f1_score(y_test, predictions_rf, average='weighted'))\n",
    "\n",
    "    report = sklearn.metrics.classification_report(y_test, predictions_gb)\n",
    "    print(\"Gradient Boosting \", i)\n",
    "    print(report)\n",
    "    gb_accuracies.append(sklearn.metrics.accuracy_score(y_test, predictions_gb))\n",
    "    gb_f1_macro.append(sklearn.metrics.f1_score(y_test, predictions_gb, average='macro'))\n",
    "    gb_f1_weighted.append(sklearn.metrics.f1_score(y_test, predictions_gb, average='weighted'))\n",
    "\n",
    "print(\"Accuracy Scores\")\n",
    "print(np.mean(rf_accuracies))\n",
    "print(np.mean(gb_accuracies))\n",
    "print(\"F1 macro scores\")\n",
    "print(np.mean(rf_f1_macro))\n",
    "print(np.mean(gb_f1_macro))\n",
    "print(\"F1 Weighted Scores\")\n",
    "print(np.mean(rf_f1_weighted))\n",
    "print(np.mean(gb_f1_weighted))\n",
    "\n",
    "print('Standard deviations')\n",
    "print(np.std(rf_accuracies))\n",
    "print(np.std(gb_accuracies))\n",
    "print(np.std(rf_f1_macro))\n",
    "print(np.std(gb_f1_macro))\n",
    "print(np.std(rf_f1_weighted))\n",
    "print(np.std(gb_f1_weighted))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "861821414808db1f617223c6d4569b19cc725b2a2a07694c74cd2c6384ef391b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('climate': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
